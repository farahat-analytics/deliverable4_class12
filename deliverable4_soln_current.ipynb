{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Carnegie Mellon University - Tepper School of Business\n",
    "##### 46-881 - Programming in R and Python - 2022 - Mini 1 - Farahat\n",
    "##### Class 12 version\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DELIVERABLE 4 - SOLUTIONS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1 (50 points)\n",
    "\n",
    "The SIR model is the original and simplest (in fact, *simplistic*) model of disease spread in epidemiology. It is a *compartmental model* where each individual in a population is classified as being in exactly one of 3 states at any gien time: **S**usceptible to infection, **I**nfectious (i.e. infected and capable of infecting susceptible individuals), or **R**ecovered (or \"removed\"). The model was developed by Kermack and McKendrick in 1927. Many improved predictive models have since been developed for disease spread. In this problem you will use Python to implement and explore this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let S(t), I(t), and R(t) denote, respectively, the number of individuals in a given population who are susceptible, infectious, and recovered on day t. The model utilizes two parameters: Beta and Gamma. For a population of size N, the time-dynamics of the model are as follows:\n",
    "- S(t+1) = S(t) - Beta * I(t) * S(t) / N\n",
    "- I(t+1) = I(t) + Beta * I(t) * S(t) / N - Gamma * I(t)\n",
    "- R(t+1) = R(t) + Gamma * I(t) \n",
    "\n",
    "The ratio Beta / Gamma is sometimes referred to as the R0 (R naught) of the disease."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Develop a Python model of the above SIR model and use it to answer the following questions. Assume a scenario where N = 1000, S(0) = 990, I(0) = 10, Beta = 0.10, and Gamma = 0.05."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "N = 1000 \n",
    "beta = 0.10\n",
    "gamma = 0.05\n",
    "S = [990]\n",
    "I = [10]\n",
    "R = [0]\n",
    "max_t = 365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note the indices correctly correspond to time\n",
    "for t in range(max_t-1):\n",
    "    S_to_I = beta * I[t] * S[t] / N\n",
    "    I_to_R = gamma * I[t]\n",
    "    S.append(S[t] - S_to_I)\n",
    "    I.append(I[t] + S_to_I - I_to_R)\n",
    "    R.append(R[t] + I_to_R) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part(a)\n",
    "Suppose our healthcare system has a capacity to accommodate a maximum of 120 infectious persons. Is this capacity sufficient according to the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160.37770863476757"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_I = max(I)\n",
    "max_I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The answer is NO. The maximum number of infectious persons peaks at 160, exceeding system capacity. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part (b)\n",
    "Now suppose that our healthcare system can currently accommodate only 120 infectious persons. However, its capacity can be increased to accommodate 180 infectious persons in 2 months. Is this current capacity and expansion plan sufficient according to the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111.74956698000823"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_I_2months = max(I[0:61]) \n",
    "max_I_2months"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The answer is YES, it is sufficient. The current capacity is sufficient over the first two months. The proposed expanded capacity is sufficient for the peak afterwards."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2 (100 points)\n",
    "\n",
    "*The purpose of this problem is to help you learn/review Python, while retaining your knowledge of R, through a direct comparison of both languages. In particular, you are asked to answer the very same exploratory data analysis questions you have answered in Problems 1 and 2 of Deliverable 3, but using Python.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer the following question based on the 2021 Healthy Ride rentals dataset(s) discussed in class September 12th - September 14th. The datasets, <rentals_all.csv> and <final_dataset.csv> are provided again accompanying this deliverable on the assignment's Canvas page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hourly = pd.read_csv(\"final_dataset.csv\")\n",
    "df_rentals = pd.read_csv(\"rentals_all.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part (a)\n",
    "Which month has the most total precipitation? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "month\n",
       "1     1.82\n",
       "2     2.95\n",
       "3     3.21\n",
       "4     2.34\n",
       "5     3.31\n",
       "6     7.45\n",
       "7     4.52\n",
       "8     6.20\n",
       "9     4.42\n",
       "10    4.50\n",
       "11    0.80\n",
       "12    4.23\n",
       "Name: precipitation, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hourly[\"precipitation\"].groupby(df_hourly[\"month\"]).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The month of June (month 6) has the most precipitation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part (b)\n",
    "How many days of the year have precipitation at some point during that day (do not count trace “T” amounts)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "143"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_pre = df_hourly[\"precipitation\"].groupby([df_hourly[\"month\"],df_hourly[\"day\"]]).sum()\n",
    "sum(daily_pre > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "143"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(daily_pre > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part (c)\n",
    "What is the average daily high temperature (maximum hourly temperature during the day) in September? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74.96428571428571"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hourly_sept = df_hourly[df_hourly[\"month\"] == 9]\n",
    "sept_grouped_daily = df_hourly_sept[\"temperature\"].groupby(df_hourly_sept[\"day\"])\n",
    "sept_daily_high = sept_grouped_daily.agg(lambda x: x.max(skipna=False))\n",
    "sept_daily_high.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part (d)\n",
    "What is the coefficient of correlation between hourly rentals and hourly windspeed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rentals</th>\n",
       "      <th>windspeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rentals</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.005181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>windspeed</th>\n",
       "      <td>0.005181</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            rentals  windspeed\n",
       "rentals    1.000000   0.005181\n",
       "windspeed  0.005181   1.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hourly[[\"rentals\",\"windspeed\"]].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlation coefficient is 0.0052 (pretty small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part (e)\n",
    "Which day of the week (Monday - Sunday) has, on average, the largest number of rentals? What is that average number of rentals?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "day_of_week\n",
       "Fri    13.347484\n",
       "Mon    12.432692\n",
       "Sat    19.044872\n",
       "Sun    15.893344\n",
       "Thu    12.092147\n",
       "Tue    13.384615\n",
       "Wed    12.599359\n",
       "Name: rentals, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hourly[\"rentals\"].groupby(df_hourly[\"day_of_week\"]).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saturday has on average the largest number of rentals with a rate of 19 rentals per hour (456 per day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part (f)\n",
    "What percentage of rentals were carried out by subscribers?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Customer      68498\n",
       "Subscriber    55095\n",
       "Name: Usertype, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rentals[\"Usertype\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subscriber rentals account for 55095 out of 123593 rentals, or 44.6%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part (g)\n",
    "Which hour of the day has, on average, the largest number of rides? Which hour has the second largest number of rentals? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hour\n",
       "0      7.734247\n",
       "1      5.054795\n",
       "2      3.961538\n",
       "3      2.701370\n",
       "4      1.202740\n",
       "5      1.465753\n",
       "6      2.161644\n",
       "7      3.643836\n",
       "8      6.967123\n",
       "9     10.443836\n",
       "10    13.210959\n",
       "11    15.728767\n",
       "12    19.652055\n",
       "13    22.550685\n",
       "14    23.487671\n",
       "15    26.208219\n",
       "16    27.808219\n",
       "17    28.339726\n",
       "18    28.827397\n",
       "19    25.920548\n",
       "20    21.347945\n",
       "21    17.084932\n",
       "22    12.956164\n",
       "23    10.180822\n",
       "Name: rentals, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hourly[\"rentals\"].groupby(df_hourly[\"hour\"]).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 6 p.m. - 7 p.m. hour followed by the 5 p.m. - 6 p.m. hour."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part (h)\n",
    "What percentage of rentals has a dockless origin? What percentage of rentals has a dockless destination? What percentage of rentals has either a dockless origin or a dockless destination?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = df_rentals.shape[0] # getting the number of rentals (equals number of rows on df_rentals dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.615695792880259"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dockless_origin = df_rentals[\"From station name\"].str.startswith(\"BIKE\")\n",
    "dockless_origin.sum() / n * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.610032362459547"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dockless_destination = df_rentals[\"To station name\"].str.startswith(\"BIKE\")\n",
    "dockless_destination.sum() / n * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.6626213592233"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dockless_either = dockless_origin | dockless_destination\n",
    "dockless_either.sum() / n * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part (i)\n",
    "What bike station (provide street address) has the most volume of outbound rentals. What bike station (provide street address) has the most volume of inbound rentals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Liberty Ave & Stanwix St                    4495\n",
       "North Shore Trail & Fort Duquesne Bridge    3834\n",
       "S Bouquet Ave & Sennott St                  3255\n",
       "S 27th St & Sidney St. (Southside Works)    3038\n",
       "Centre Ave & N Craig St                     2924\n",
       "                                            ... \n",
       "BIKE 70482                                     1\n",
       "70234                                          1\n",
       "BIKE 70934                                     1\n",
       "BIKE 70151 - doubletree                        1\n",
       "BIKE 70317                                     1\n",
       "Name: From station name, Length: 767, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rentals[\"From station name\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Liberty Ave & Stanwix St has the most volume of outbound rentals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Liberty Ave & Stanwix St                     4796\n",
       "North Shore Trail & Fort Duquesne Bridge     3963\n",
       "S Bouquet Ave & Sennott St                   3307\n",
       "S 27th St & Sidney St. (Southside Works)     3267\n",
       "Schenley Dr & Forbes Ave (Schenley Plaza)    2997\n",
       "                                             ... \n",
       "Fort Pitt Museum                                1\n",
       "recording_120320969                             1\n",
       "recording_113911594                             1\n",
       "BIKE 70692                                      1\n",
       "Frankstown Ave & Eastview St                    1\n",
       "Name: To station name, Length: 832, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rentals[\"To station name\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Liberty Ave & Stanwix St also has the most volume of inbound rentals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part (j)\n",
    "Which pair of stations has the most number of rentals between them (add the rentals in each direction)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can follow the same approach described for Problem 1(f) of Deliverable 3 (you can review the solution beforehand). The idea is to arrange each pair of stations alphabetically then group by distinct pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\afarahat\\AppData\\Local\\Temp\\ipykernel_10592\\3233856748.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"alpha_first\"] = df.apply(lambda x: min(str(x[\"From station name\"]), str(x[\"To station name\"])),\n",
      "C:\\Users\\afarahat\\AppData\\Local\\Temp\\ipykernel_10592\\3233856748.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"alpha_second\"] = df.apply(lambda x: max(str(x[\"From station name\"]), str(x[\"To station name\"])),\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "alpha_first                               alpha_second                                         \n",
       "Liberty Ave & Stanwix St                  Liberty Ave & Stanwix St                                 2291\n",
       "North Shore Trail & Fort Duquesne Bridge  North Shore Trail & Fort Duquesne Bridge                 2189\n",
       "33rd St & Penn Ave                        33rd St & Penn Ave                                       1711\n",
       "S 27th St & Sidney St. (Southside Works)  S 27th St & Sidney St. (Southside Works)                 1337\n",
       "Microsoft                                 Microsoft                                                1001\n",
       "                                                                                                   ... \n",
       "BIKE 70642                                Frew St & Schenley Dr                                       1\n",
       "                                          S Bouquet Ave & Sennott St                                  1\n",
       "                                          Schenley Dr at Schenley Plaza (Carnegie Library Main)       1\n",
       "                                          Wightman St & Forbes Ave                                    1\n",
       "recording_119278362                       recording_119278362                                         1\n",
       "Length: 13640, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To guarantee that alphabetical ordering works properly, \n",
    "# we'll first ensure that From and To stations names are string arrays.\n",
    "df = df_rentals[[\"From station name\", \"To station name\"]]\n",
    "\n",
    "df[\"alpha_first\"] = df.apply(lambda x: min(str(x[\"From station name\"]), str(x[\"To station name\"])),\n",
    "                             axis=1)\n",
    "\n",
    "df[\"alpha_second\"] = df.apply(lambda x: max(str(x[\"From station name\"]), str(x[\"To station name\"])),\n",
    "                             axis=1)\n",
    "\n",
    "df = df.drop([\"From station name\", \"To station name\"], axis = 1)\n",
    "\n",
    "#df_distinct = df[df[\"alpha_first\"] != df[\"alpha_second\"]]\n",
    "\n",
    "df.groupby([df[\"alpha_first\"],df[\"alpha_second\"]]).value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On average then, the number of rides originating and ending at the Liberty Ave & Stanwix St station (2291 rides) exceed the number of rides between any other pair of stations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3 (50 points)\n",
    "\n",
    "Suppose you drive a car whose fuel efficiency is 18 miles per gallon and whose gas tank size is 16 gallons. Gas prices fluctuate according to a **uniform distribution** ranging from 3 dollars per gallon to 5 dollars per gallon. That is, prices remain average equal to 4 dollars per gallon but fluctuate each day according to this uniform distribution. Every day you drive your car for exactly 10 miles.\n",
    "\n",
    "You are contemplating two gas filling strategies:\n",
    "- *“Fill-it up” strategy*: You wait till the tank is (almost) empty then fill the entire tank;\n",
    "- *“30-dollar” strategy*: You wait till the tank is (almost) empty then fill in only 30 dollars worth of gas.\n",
    "\n",
    "Assume that there are many gas stations around, so you can time your visits almost exactly when the tank is empty. Assume also that any inconvenience from visiting the gas station is negligible. Your only objective is to minimize your gas expenditure.\n",
    "\n",
    "***Construct a simulation model in Python to determine if one strategy is more economical than the other (and, if so, by how much).*** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common parameters:\n",
    "efficiency = 18 # miles per gallon\n",
    "daily_distance = 10 # miles\n",
    "price_low = 3 # dollars per gallon\n",
    "price_high = 5 # dollars per gallon\n",
    "\n",
    "# Fill-it up strategy parameters:\n",
    "fill_gallons = 16\n",
    "\n",
    "# Fill-it up strategy parameters:\n",
    "fill_dollars = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two simulation approaches below are equivalent and yield the same conclusion: **the 30 dollar strategy is more economical, but not by much (about 8 cents)**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation Approach 1: Fixed number of fills"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fill-it up strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.001126688157896"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_refills = 100_000 # number of trials in simulation\n",
    "dollars_paid_list = []\n",
    "random.seed(881)\n",
    "\n",
    "for i in range(num_refills):\n",
    "    price = random.uniform(price_low, price_high)\n",
    "    dollars_paid_list.append(fill_gallons*price)\n",
    "    \n",
    "av_price_per_gallon = sum(dollars_paid_list) / (num_refills * fill_gallons)  \n",
    "\n",
    "av_price_per_gallon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 30-dollar strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.916118376400644"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_refills = 100_000 # number of trials in simulation\n",
    "gallons_filled_list = []\n",
    "random.seed(881)\n",
    "\n",
    "for i in range(num_refills):\n",
    "    price = random.uniform(price_low, price_high)\n",
    "    gallons_filled_list.append(fill_dollars / price)\n",
    "    \n",
    "av_price_per_gallon = (num_refills * fill_dollars) / sum(gallons_filled_list) \n",
    "\n",
    "av_price_per_gallon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation Approach 2: Fixed elapsed time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fill-it up strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.9999830051639154"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elapsed_time = 10_000_000 # number of *days* elapsed\n",
    "t = 0\n",
    "total_gallons_purchased = 0\n",
    "total_dollars_spent = 0\n",
    "\n",
    "random.seed(881)\n",
    "\n",
    "while t < elapsed_time:\n",
    "    price = random.uniform(price_low, price_high)\n",
    "    gallons_purchased = fill_gallons\n",
    "    dollars_spent = fill_gallons * price\n",
    "    total_gallons_purchased += gallons_purchased\n",
    "    total_dollars_spent += dollars_spent\n",
    "    t += gallons_purchased * efficiency / daily_distance\n",
    "    \n",
    "av_price_per_gallon = total_dollars_spent / total_gallons_purchased  \n",
    "av_price_per_gallon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 30-dollar strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.9152087996901366"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elapsed_time = 10_000_000 # number of *days* elapsed\n",
    "t = 0\n",
    "total_gallons_purchased = 0\n",
    "total_dollars_spent = 0\n",
    "\n",
    "random.seed(881)\n",
    "\n",
    "while t < elapsed_time:\n",
    "    price = random.uniform(price_low, price_high)\n",
    "    gallons_purchased = fill_dollars / price\n",
    "    dollars_spent = fill_dollars\n",
    "    total_gallons_purchased += gallons_purchased\n",
    "    total_dollars_spent += dollars_spent\n",
    "    t += gallons_purchased * efficiency / daily_distance\n",
    "    \n",
    "av_price_per_gallon = total_dollars_spent / total_gallons_purchased  \n",
    "av_price_per_gallon"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "cbEQlIplwY5k",
    "EBUEG5-Cnglm",
    "HBHgRvCEzJAD",
    "IeWbEvilxC5P",
    "Rhly7BwrzPdf",
    "neI3PXRV5Y5f",
    "t5h7PZ-Q6L09",
    "0Nlsk4V16P08",
    "fnWLIf0r_POH",
    "rnvyAlV5_mMz",
    "OQk3oN_T_yl2",
    "2FCZXiuY_uIf",
    "GS1h4S8LvHyJ"
   ],
   "name": "2021_10_01_meeting.ipynb",
   "provenance": []
  },
  "finalized": {
   "timestamp": 1653670308085,
   "trusted": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
